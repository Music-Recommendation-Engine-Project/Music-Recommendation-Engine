{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, functions as F\n",
    "import os\n",
    "from pyspark.sql.functions import explode\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"reco\") \\\n",
    "    .config(\"spark.master\", \"local[*]\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get all the files in a directory\n",
    "def get_files(path):\n",
    "    print(\"Getting files from {}\".format(path))\n",
    "    files = []\n",
    "    for file in os.listdir(path):\n",
    "        if file.endswith(\".json\"):\n",
    "            files.append(os.path.join(path, file))\n",
    "\n",
    "    # Group the files in batches of 10\n",
    "    batches = []\n",
    "    for i in range(0, len(files), 5):\n",
    "        batches.append(files[i : i + 5])\n",
    "        print(\"Batch {} - {}\".format(i, i + 5), \" ready to be processed.\")\n",
    "        print(\"------------------\")\n",
    "\n",
    "    return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting files from Dataset/spotify_playlists\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'Dataset/spotify_playlists'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\juan\\My Drive\\AAUniversidad\\AAsignaturas\\Third Year\\BCSAI_22_23_THIRD__Q2\\AI CHATBOTS & RECOMMENDATION ENGINES\\ETL_playlist_versionfinal.ipynb Cell 4\u001b[0m in \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/juan/My%20Drive/AAUniversidad/AAsignaturas/Third%20Year/BCSAI_22_23_THIRD__Q2/AI%20CHATBOTS%20%26%20RECOMMENDATION%20ENGINES/ETL_playlist_versionfinal.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Read the data\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/juan/My%20Drive/AAUniversidad/AAsignaturas/Third%20Year/BCSAI_22_23_THIRD__Q2/AI%20CHATBOTS%20%26%20RECOMMENDATION%20ENGINES/ETL_playlist_versionfinal.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m path \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mDataset/spotify_playlists\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/juan/My%20Drive/AAUniversidad/AAsignaturas/Third%20Year/BCSAI_22_23_THIRD__Q2/AI%20CHATBOTS%20%26%20RECOMMENDATION%20ENGINES/ETL_playlist_versionfinal.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m groups \u001b[39m=\u001b[39m get_files(path)\n",
      "\u001b[1;32mc:\\Users\\juan\\My Drive\\AAUniversidad\\AAsignaturas\\Third Year\\BCSAI_22_23_THIRD__Q2\\AI CHATBOTS & RECOMMENDATION ENGINES\\ETL_playlist_versionfinal.ipynb Cell 4\u001b[0m in \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/juan/My%20Drive/AAUniversidad/AAsignaturas/Third%20Year/BCSAI_22_23_THIRD__Q2/AI%20CHATBOTS%20%26%20RECOMMENDATION%20ENGINES/ETL_playlist_versionfinal.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mGetting files from \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(path))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/juan/My%20Drive/AAUniversidad/AAsignaturas/Third%20Year/BCSAI_22_23_THIRD__Q2/AI%20CHATBOTS%20%26%20RECOMMENDATION%20ENGINES/ETL_playlist_versionfinal.ipynb#W3sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m files \u001b[39m=\u001b[39m []\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/juan/My%20Drive/AAUniversidad/AAsignaturas/Third%20Year/BCSAI_22_23_THIRD__Q2/AI%20CHATBOTS%20%26%20RECOMMENDATION%20ENGINES/ETL_playlist_versionfinal.ipynb#W3sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m file \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39;49mlistdir(path):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/juan/My%20Drive/AAUniversidad/AAsignaturas/Third%20Year/BCSAI_22_23_THIRD__Q2/AI%20CHATBOTS%20%26%20RECOMMENDATION%20ENGINES/ETL_playlist_versionfinal.ipynb#W3sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39mif\u001b[39;00m file\u001b[39m.\u001b[39mendswith(\u001b[39m\"\u001b[39m\u001b[39m.json\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/juan/My%20Drive/AAUniversidad/AAsignaturas/Third%20Year/BCSAI_22_23_THIRD__Q2/AI%20CHATBOTS%20%26%20RECOMMENDATION%20ENGINES/ETL_playlist_versionfinal.ipynb#W3sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m         files\u001b[39m.\u001b[39mappend(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(path, file))\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'Dataset/spotify_playlists'"
     ]
    }
   ],
   "source": [
    "# Read the data\n",
    "path = \"Dataset/spotify_playlists\"\n",
    "groups = get_files(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the files in batches of 10 to avoid memory issues\n",
    "for group in groups[:10]:\n",
    "    print(\"------------------\")\n",
    "\n",
    "    print(\"Reading group: \", groups.index(group) + 1, \" of \", len(groups))\n",
    "    data = spark.read.json(group, multiLine=True)\n",
    "    data.createOrReplaceTempView(\"data\")\n",
    "    print(\"Finished reading group: \", groups.index(group) + 1, \" of \", len(groups))\n",
    "\n",
    "    playlist = data.select(explode(\"playlists.tracks\").alias(\"tracks\"))\n",
    "    df = playlist.select(\"tracks.track_name\", \"tracks.track_uri\", \"tracks.artist_uri\", \"tracks.album_uri\")\n",
    "\n",
    "    # Add a column with the index of the playlist\n",
    "    df = df.withColumn(\"playlist_id\", F.monotonically_increasing_id())\n",
    "\n",
    "    # Cache the dataframe in memory\n",
    "    df.cache()\n",
    "\n",
    "    # Define a function to convert a row of the dataframe to a list of songs\n",
    "    def row_to_songs(row):\n",
    "        # Go through each value in the row and append it to the list\n",
    "        songs_df = []\n",
    "        for i in range(len(row['track_name'])):\n",
    "            songs_df.append([row['track_name'][i], row['track_uri'][i], row['artist_uri'][i], row['album_uri'][i], row['playlist_id']])\n",
    "        return songs_df\n",
    "\n",
    "    print(\"------------------\")\n",
    "    \n",
    "    # Use df.rdd.map() to apply the row_to_songs() function to each row of the dataframe in parallel\n",
    "    all_songs_rdd = df.rdd.map(row_to_songs)\n",
    "\n",
    "    # Convert the RDD to a list\n",
    "    all_songs = all_songs_rdd.collect()\n",
    "\n",
    "    # print(\"Finish converting the dataframe to a list of songs in group: \", str(groups.index(group)))\n",
    "\n",
    "    # Save the file to disk\n",
    "    with open('Dataset/temp_data/' + str(groups.index(group)) + '.pkl', 'wb') as f:\n",
    "        pickle.dump(all_songs, f)\n",
    "        print(\"Document saved to disk\")\n",
    "\n",
    "\n",
    "    # Unpersist the dataframe from memory\n",
    "    df.unpersist()\n",
    "\n",
    "    print(\"------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting files from Dataset/spotify_playlists\n",
      "Batch 0 - 5  ready to be processed.\n",
      "------------------\n",
      "Batch 5 - 10  ready to be processed.\n",
      "------------------\n",
      "Batch 10 - 15  ready to be processed.\n",
      "------------------\n",
      "Batch 15 - 20  ready to be processed.\n",
      "------------------\n",
      "Batch 20 - 25  ready to be processed.\n",
      "------------------\n",
      "Batch 25 - 30  ready to be processed.\n",
      "------------------\n",
      "Batch 30 - 35  ready to be processed.\n",
      "------------------\n",
      "Batch 35 - 40  ready to be processed.\n",
      "------------------\n",
      "Batch 40 - 45  ready to be processed.\n",
      "------------------\n",
      "Batch 45 - 50  ready to be processed.\n",
      "------------------\n",
      "Batch 50 - 55  ready to be processed.\n",
      "------------------\n",
      "Batch 55 - 60  ready to be processed.\n",
      "------------------\n",
      "Batch 60 - 65  ready to be processed.\n",
      "------------------\n",
      "Batch 65 - 70  ready to be processed.\n",
      "------------------\n",
      "Batch 70 - 75  ready to be processed.\n",
      "------------------\n",
      "Batch 75 - 80  ready to be processed.\n",
      "------------------\n",
      "Batch 80 - 85  ready to be processed.\n",
      "------------------\n",
      "Batch 85 - 90  ready to be processed.\n",
      "------------------\n",
      "Batch 90 - 95  ready to be processed.\n",
      "------------------\n",
      "Batch 95 - 100  ready to be processed.\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "Reading group:  11  of  20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished reading group:  11  of  20\n",
      "------------------\n",
      "Exploding the data\n",
      "Finished exploding the data\n",
      "------------------\n",
      "------------------\n",
      "Converting the dataframe to a list of songs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document saved to disk\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "Reading group:  12  of  20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished reading group:  12  of  20\n",
      "------------------\n",
      "Exploding the data\n",
      "Finished exploding the data\n",
      "------------------\n",
      "------------------\n",
      "Converting the dataframe to a list of songs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document saved to disk\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "Reading group:  13  of  20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished reading group:  13  of  20\n",
      "------------------\n",
      "Exploding the data\n",
      "Finished exploding the data\n",
      "------------------\n",
      "------------------\n",
      "Converting the dataframe to a list of songs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document saved to disk\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "Reading group:  14  of  20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished reading group:  14  of  20\n",
      "------------------\n",
      "Exploding the data\n",
      "Finished exploding the data\n",
      "------------------\n",
      "------------------\n",
      "Converting the dataframe to a list of songs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document saved to disk\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "Reading group:  15  of  20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished reading group:  15  of  20\n",
      "------------------\n",
      "Exploding the data\n",
      "Finished exploding the data\n",
      "------------------\n",
      "------------------\n",
      "Converting the dataframe to a list of songs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document saved to disk\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "Reading group:  16  of  20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished reading group:  16  of  20\n",
      "------------------\n",
      "Exploding the data\n",
      "Finished exploding the data\n",
      "------------------\n",
      "------------------\n",
      "Converting the dataframe to a list of songs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document saved to disk\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "Reading group:  17  of  20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished reading group:  17  of  20\n",
      "------------------\n",
      "Exploding the data\n",
      "Finished exploding the data\n",
      "------------------\n",
      "------------------\n",
      "Converting the dataframe to a list of songs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document saved to disk\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "Reading group:  18  of  20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished reading group:  18  of  20\n",
      "------------------\n",
      "Exploding the data\n",
      "Finished exploding the data\n",
      "------------------\n",
      "------------------\n",
      "Converting the dataframe to a list of songs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document saved to disk\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "Reading group:  19  of  20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished reading group:  19  of  20\n",
      "------------------\n",
      "Exploding the data\n",
      "Finished exploding the data\n",
      "------------------\n",
      "------------------\n",
      "Converting the dataframe to a list of songs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document saved to disk\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "------------------\n",
      "Reading group:  20  of  20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished reading group:  20  of  20\n",
      "------------------\n",
      "Exploding the data\n",
      "Finished exploding the data\n",
      "------------------\n",
      "------------------\n",
      "Converting the dataframe to a list of songs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document saved to disk\n",
      "------------------\n",
      "------------------\n"
     ]
    }
   ],
   "source": [
    "# Group the files in batches of 10 to avoid memory issues, and save the data to disk\n",
    "for group in groups[10:]:\n",
    "    print(\"------------------\")\n",
    "\n",
    "    print(\"Reading group: \", groups.index(group) + 1, \" of \", len(groups))\n",
    "    data = spark.read.json(group, multiLine=True)\n",
    "    data.createOrReplaceTempView(\"data\")\n",
    "    print(\"Finished reading group: \", groups.index(group) + 1, \" of \", len(groups))\n",
    "\n",
    "    playlist = data.select(explode(\"playlists.tracks\").alias(\"tracks\"))\n",
    "    df = playlist.select(\"tracks.track_name\", \"tracks.track_uri\", \"tracks.artist_uri\", \"tracks.album_uri\")\n",
    "\n",
    "    # Add a column with the index of the playlist\n",
    "    df = df.withColumn(\"playlist_id\", F.monotonically_increasing_id())\n",
    "\n",
    "    # Cache the dataframe in memory\n",
    "    df.cache()\n",
    "\n",
    "    # Define a function to convert a row of the dataframe to a list of songs\n",
    "    def row_to_songs(row):\n",
    "        # Go through each value in the row and append it to the list\n",
    "        songs_df = []\n",
    "        for i in range(len(row['track_name'])):\n",
    "            songs_df.append([row['track_name'][i], row['track_uri'][i], row['artist_uri'][i], row['album_uri'][i], row['playlist_id']])\n",
    "        return songs_df\n",
    "\n",
    "    print(\"------------------\")\n",
    "    \n",
    "    # Use df.rdd.map() to apply the row_to_songs() function to each row of the dataframe in parallel\n",
    "    all_songs_rdd = df.rdd.map(row_to_songs)\n",
    "\n",
    "    # Convert the RDD to a list\n",
    "    all_songs = all_songs_rdd.collect()\n",
    "\n",
    "    # print(\"Finish converting the dataframe to a list of songs in group: \", str(groups.index(group)))\n",
    "\n",
    "    # Save the file to disk\n",
    "    with open('Dataset/temp_data/' + str(groups.index(group)) + '.pkl', 'wb') as f:\n",
    "        pickle.dump(all_songs, f)\n",
    "        print(\"Document saved to disk\")\n",
    "\n",
    "\n",
    "    # Unpersist the dataframe from memory\n",
    "    df.unpersist()\n",
    "\n",
    "    print(\"------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ge the column names of the all_songs list\n",
    "columns = ['track_name', 'track_uri', 'artist_uri', 'album_uri', 'playlist_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all the files pkl files into one list\n",
    "all_songs_merge = []\n",
    "for group in groups[:10]:\n",
    "    print(\"------------------\")\n",
    "    with open('Dataset/temp_data/' + str(groups.index(group)) + '.pkl', 'rb') as f:\n",
    "        all_songs_merge.extend(pickle.load(f)) \n",
    "        print(\"Document loaded from disk\", \"Group: \", str(groups.index(group)))\n",
    "\n",
    "        # When read the file, delete the file\n",
    "        # os.remove('Dataset/temp_data/' + str(groups.index(group)) + '.pkl')\n",
    "        # print(\"Document deleted from disk\")\n",
    "    print(\"------------------\")\n",
    "\n",
    "print(\"Finished merging all the files\")\n",
    "\n",
    "print(\"Converting the list to a dataframe\")\n",
    "# Convert the list to a dataframe\n",
    "all_songs_df = pd.DataFrame([item for sublist in all_songs_merge for item in sublist], columns=columns)\n",
    "\n",
    "print(\"Data frame created, shape: \", all_songs_df.shape)\n",
    "\n",
    "# Merge the duplicate rows into one adding the playlists to the playlists column in a array\n",
    "all_songs_df_grouped = all_songs_df.groupby(['track_name', 'track_uri', 'artist_uri', 'album_uri'])['playlist_id'].apply(list).reset_index()\n",
    "\n",
    "print(\"Data grouped, shape: \", all_songs_df_grouped.shape)\n",
    "\n",
    "\n",
    "# new column with the number of playlists\n",
    "all_songs_df_grouped['playlist_count'] = all_songs_df_grouped['playlist_id'].apply(lambda x: len(set(x)))\n",
    "\n",
    "# Sort the dataframe by the number of playlistsç\n",
    "all_songs_df_grouped = all_songs_df_grouped.sort_values(by=['playlist_count'], ascending=False)\n",
    "\n",
    "# Safe the dataframe to a csv file with the name of the group\n",
    "all_songs_df_grouped.to_csv('Dataset/datafull1.csv', index=False)\n",
    "\n",
    "print(\"Data saved to csv\")\n",
    "print(\"------------------\")\n",
    "print(\"Finished processing the data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------\n",
      "Document loaded from disk Group:  10\n",
      "------------------\n",
      "------------------\n",
      "Document loaded from disk Group:  11\n",
      "------------------\n",
      "------------------\n",
      "Document loaded from disk Group:  12\n",
      "------------------\n",
      "------------------\n",
      "Document loaded from disk Group:  13\n",
      "------------------\n",
      "------------------\n",
      "Document loaded from disk Group:  14\n",
      "------------------\n",
      "------------------\n",
      "Document loaded from disk Group:  15\n",
      "------------------\n",
      "------------------\n",
      "Document loaded from disk Group:  16\n",
      "------------------\n",
      "------------------\n",
      "Document loaded from disk Group:  17\n",
      "------------------\n",
      "------------------\n",
      "Document loaded from disk Group:  18\n",
      "------------------\n",
      "------------------\n",
      "Document loaded from disk Group:  19\n",
      "------------------\n",
      "Finished merging all the files\n",
      "Converting the list to a dataframe\n",
      "Data frame created, shape:  (3331480, 5)\n",
      "Data grouped, shape:  (456346, 5)\n",
      "Data saved to csv\n",
      "------------------\n",
      "Finished processing the data\n"
     ]
    }
   ],
   "source": [
    "# Merge all the files pkl files into one list\n",
    "all_songs_merge = []\n",
    "for group in groups[10:]:\n",
    "    print(\"------------------\")\n",
    "    with open('Dataset/temp_data/' + str(groups.index(group)) + '.pkl', 'rb') as f:\n",
    "        all_songs_merge.extend(pickle.load(f)) \n",
    "        print(\"Document loaded from disk\", \"Group: \", str(groups.index(group)))\n",
    "\n",
    "        # When read the file, delete the file\n",
    "        # os.remove('Dataset/temp_data/' + str(groups.index(group)) + '.pkl')\n",
    "        # print(\"Document deleted from disk\")\n",
    "    print(\"------------------\")\n",
    "\n",
    "print(\"Finished merging all the files\")\n",
    "\n",
    "print(\"Converting the list to a dataframe\")\n",
    "# Convert the list to a dataframe\n",
    "all_songs_df = pd.DataFrame([item for sublist in all_songs_merge for item in sublist], columns=columns)\n",
    "\n",
    "print(\"Data frame created, shape: \", all_songs_df.shape)\n",
    "\n",
    "# Merge the duplicate rows into one adding the playlists to the playlists column in a array\n",
    "all_songs_df_grouped = all_songs_df.groupby(['track_name', 'track_uri', 'artist_uri', 'album_uri'])['playlist_id'].apply(list).reset_index()\n",
    "\n",
    "print(\"Data grouped, shape: \", all_songs_df_grouped.shape)\n",
    "\n",
    "\n",
    "# new column with the number of playlists\n",
    "all_songs_df_grouped['playlist_count'] = all_songs_df_grouped['playlist_id'].apply(lambda x: len(set(x)))\n",
    "\n",
    "# Sort the dataframe by the number of playlistsç\n",
    "all_songs_df_grouped = all_songs_df_grouped.sort_values(by=['playlist_count'], ascending=False)\n",
    "\n",
    "# Safe the dataframe to a csv file with the name of the group\n",
    "all_songs_df_grouped.to_csv('Dataset/datafull2.csv', index=False)\n",
    "\n",
    "print(\"Data saved to csv\")\n",
    "print(\"------------------\")\n",
    "print(\"Finished processing the data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge datafull2.csv with datafull1.csv, they have in common the columns: track_name, track_uri, artist_uri, album_uri, then combine the playlists_id and playlist_count columns\n",
    "import pandas as pd\n",
    "# Read the data\n",
    "df1 = pd.read_csv('Dataset/datafull1.csv')\n",
    "df2 = pd.read_csv('Dataset/datafull2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "df1[\"playlist_id\"] = df1[\"playlist_id\"].apply(lambda x: ast.literal_eval(x))\n",
    "df2[\"playlist_id\"] = df2[\"playlist_id\"].apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "# change the type of the values on each array in the arrays in the playlist_id column\n",
    "df1[\"playlist_id\"] = df1[\"playlist_id\"].apply(lambda x: [str(i) for i in x])\n",
    "df2[\"playlist_id\"] = df2[\"playlist_id\"].apply(lambda x: [str(i) for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in df1:  462812\n",
      "Number of rows in df2:  456346\n",
      "Total number of rows:  919158\n",
      "Number of songs in common:  237353\n",
      "Outer join length:  681805\n",
      "Outer join + common songs:  919158\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# print the number of rows in each dataframe\n",
    "print(\"Number of rows in df1: \", df1.shape[0])\n",
    "print(\"Number of rows in df2: \", df2.shape[0])\n",
    "# total number of rows\n",
    "print(\"Total number of rows: \", df1.shape[0] + df2.shape[0])\n",
    "# How many songs are in common\n",
    "print(\"Number of songs in common: \", len(set(df1['track_uri']).intersection(set(df2['track_uri']))))\n",
    "\n",
    "# Outer join length\n",
    "print(\"Outer join length: \", len(set(df1['track_uri']).union(set(df2['track_uri']))))\n",
    "\n",
    "# outer join + common songs\n",
    "print(\"Outer join + common songs: \", len(set(df1['track_uri']).union(set(df2['track_uri']))) + len(set(df1['track_uri']).intersection(set(df2['track_uri']))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_common = pd.merge(df1, df2, how='inner', on=['track_name', 'track_uri', 'artist_uri', 'album_uri'])\n",
    "# Concatenate the playlist_id columns\n",
    "df_common['playlist_id'] = df_common['playlist_id_x'] + df_common['playlist_id_y']\n",
    "# compute the number of playlists for x and y\n",
    "df_common['playlist_count_x'] = df_common['playlist_id_x'].apply(lambda x: len(set(x)))\n",
    "df_common['playlist_count_y'] = df_common['playlist_id_y'].apply(lambda x: len(set(x)))\n",
    "# new column with the combination of playlist_id_x and playlist_id_y unique values in a column id  and the number of playlists in a column count\n",
    "df_common['playlist_id'] = df_common['playlist_id'].apply(lambda x: list(set(x)))\n",
    "df_common['playlist_count'] = df_common['playlist_id'].apply(lambda x: len(set(x)))\n",
    "\n",
    "# Drop the columns playlist_id_x, playlist_id_y, playlist_count_x, playlist_count_y\n",
    "df_common = df_common.drop(columns=['playlist_id_x', 'playlist_id_y', 'playlist_count_x', 'playlist_count_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "237353"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juan\\AppData\\Local\\Temp\\ipykernel_9640\\4069587794.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_outter_only_df1['playlist_id'] = df_outter_only_df1['playlist_id_x']\n",
      "C:\\Users\\juan\\AppData\\Local\\Temp\\ipykernel_9640\\4069587794.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_outter_only_df2['playlist_id'] = df_outter_only_df2['playlist_id_y']\n",
      "C:\\Users\\juan\\AppData\\Local\\Temp\\ipykernel_9640\\4069587794.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_outter_only_df1['playlist_count'] = df_outter_only_df1['playlist_id_x'].apply(lambda x: len(set(x)))\n",
      "C:\\Users\\juan\\AppData\\Local\\Temp\\ipykernel_9640\\4069587794.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_outter_only_df2['playlist_count'] = df_outter_only_df2['playlist_id_y'].apply(lambda x: len(set(x)))\n"
     ]
    }
   ],
   "source": [
    "# Outter minus join\n",
    "df_outter = pd.merge(df1, df2, how='outer', on=['track_name', 'track_uri', 'artist_uri', 'album_uri'], indicator=True)\n",
    "# Select the rows that are only in df1\n",
    "df_outter_only_df1 = df_outter[df_outter['_merge'] == 'left_only']\n",
    "# Select the rows that are only in df2\n",
    "df_outter_only_df2 = df_outter[df_outter['_merge'] == 'right_only']\n",
    "\n",
    "# Concatenate the playlist_id columns\n",
    "df_outter_only_df1['playlist_id'] = df_outter_only_df1['playlist_id_x']\n",
    "df_outter_only_df2['playlist_id'] = df_outter_only_df2['playlist_id_y']\n",
    "\n",
    "# compute the number of playlists for x and y\n",
    "df_outter_only_df1['playlist_count'] = df_outter_only_df1['playlist_id_x'].apply(lambda x: len(set(x)))\n",
    "df_outter_only_df2['playlist_count'] = df_outter_only_df2['playlist_id_y'].apply(lambda x: len(set(x)))\n",
    "\n",
    "# Drop the columns that are not needed\n",
    "df_outter_only_df1 = df_outter_only_df1.drop(['playlist_id_x', 'playlist_id_y', 'playlist_count_x', 'playlist_count_y', '_merge'], axis=1)\n",
    "df_outter_only_df2 = df_outter_only_df2.drop(['playlist_id_x', 'playlist_id_y', 'playlist_count_x', 'playlist_count_y', '_merge'], axis=1)\n",
    "\n",
    "# Concatenate the two dataframes\n",
    "df_outter = pd.concat([df_outter_only_df1, df_outter_only_df2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "444452"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_outter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_name</th>\n",
       "      <th>track_uri</th>\n",
       "      <th>artist_uri</th>\n",
       "      <th>album_uri</th>\n",
       "      <th>playlist_id</th>\n",
       "      <th>playlist_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [track_name, track_uri, artist_uri, album_uri, playlist_id, playlist_count]\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_common[df_common.duplicated(subset=['track_uri'], keep=False)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_name</th>\n",
       "      <th>track_uri</th>\n",
       "      <th>artist_uri</th>\n",
       "      <th>album_uri</th>\n",
       "      <th>playlist_id</th>\n",
       "      <th>playlist_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [track_name, track_uri, artist_uri, album_uri, playlist_id, playlist_count]\n",
       "Index: []"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find duplicates in df_outter\n",
    "df_outter[df_outter.duplicated(subset=['track_uri'], keep=False)]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_name</th>\n",
       "      <th>track_uri</th>\n",
       "      <th>artist_uri</th>\n",
       "      <th>album_uri</th>\n",
       "      <th>playlist_id</th>\n",
       "      <th>playlist_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HUMBLE.</td>\n",
       "      <td>spotify:track:7KXjTSCq5nL1LoYtL7XAwS</td>\n",
       "      <td>spotify:artist:2YZyLoL8N0Wb9xBt1NhZWg</td>\n",
       "      <td>spotify:album:4eLPsYPBmXABThSJ821sqY</td>\n",
       "      <td>[17179869726, 34359739337, 17179869700, 171798...</td>\n",
       "      <td>2929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Closer</td>\n",
       "      <td>spotify:track:7BKLCZ1jbUBVqRi2FVlTVw</td>\n",
       "      <td>spotify:artist:69GGBxA162lTqCwzJG5jLp</td>\n",
       "      <td>spotify:album:0rSLgV8p5FzfnqlEk4GzxE</td>\n",
       "      <td>[190, 34359738397, 17179869700, 17179869260, 3...</td>\n",
       "      <td>2832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>One Dance</td>\n",
       "      <td>spotify:track:1xznGGDReH1oQq0xzbwXa3</td>\n",
       "      <td>spotify:artist:3TVXtAsR1Inumwj472S9r4</td>\n",
       "      <td>spotify:album:3hARKC8cinq3mZLLAEaBh9</td>\n",
       "      <td>[17179869726, 190, 17179869260, 8589935195, 34...</td>\n",
       "      <td>2825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Broccoli (feat. Lil Yachty)</td>\n",
       "      <td>spotify:track:7yyRTcZmCiyzzJlNzGC9Ol</td>\n",
       "      <td>spotify:artist:5M0lbkGluOPXLeFjApw8r8</td>\n",
       "      <td>spotify:album:0NrZHZ0y5kTO8EHliuUUca</td>\n",
       "      <td>[34359738917, 190, 34359738448, 8589935195, 34...</td>\n",
       "      <td>2793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Congratulations</td>\n",
       "      <td>spotify:track:3a1lNhkSLSkpJE4MSHpDu9</td>\n",
       "      <td>spotify:artist:246dkjvS1zLTtiykXe5h60</td>\n",
       "      <td>spotify:album:5s0rmjP8XOPhP6HhqOhuyC</td>\n",
       "      <td>[34359738917, 190, 17179869700, 34359738397, 3...</td>\n",
       "      <td>2733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681800</th>\n",
       "      <td>Intro Bonito</td>\n",
       "      <td>spotify:track:19pUiFzM1Lfui5IzvbJInJ</td>\n",
       "      <td>spotify:artist:6OqhFYFJDnBBHas02HopPT</td>\n",
       "      <td>spotify:album:2xyl7MxdxOGd7m8qV6mtcM</td>\n",
       "      <td>[8589935151]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681801</th>\n",
       "      <td>Intro / Mule Skinner Blues (Blue Yodel No. 8) ...</td>\n",
       "      <td>spotify:track:3IOJXkHcwFDTOSLxcAw2XF</td>\n",
       "      <td>spotify:artist:64vAECmFoB6mi7n1zTRwR8</td>\n",
       "      <td>spotify:album:1XXMBnpx20DkGNyiuf4TPa</td>\n",
       "      <td>[25769804664]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681802</th>\n",
       "      <td>Intro / Madness</td>\n",
       "      <td>spotify:track:62KdOlGDRX7jbQJLIivG5j</td>\n",
       "      <td>spotify:artist:75S63f1AmZUa9gpQvlt5NB</td>\n",
       "      <td>spotify:album:6etmKrHivh8W7SouljN2si</td>\n",
       "      <td>[8589934677]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681803</th>\n",
       "      <td>Intro - Urban Salute to Hector Lavoe</td>\n",
       "      <td>spotify:track:5krfvR6iPmNbXalFgmtvPS</td>\n",
       "      <td>spotify:artist:6P9Adm5Ne2YtzhV1hOjQcC</td>\n",
       "      <td>spotify:album:4Hf8SuY3DNK07Q8cagjCNR</td>\n",
       "      <td>[17179869244]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681804</th>\n",
       "      <td>Look For Me At Jesus' Feet - Live</td>\n",
       "      <td>spotify:track:1wNYmgrFCHQQeJ1oRKPrvl</td>\n",
       "      <td>spotify:artist:01uI1SCsA0pLwWa2ENV6Gv</td>\n",
       "      <td>spotify:album:3FabM2BjqVC3hlIfzP4sA2</td>\n",
       "      <td>[815]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>681805 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               track_name  \\\n",
       "0                                                 HUMBLE.   \n",
       "1                                                  Closer   \n",
       "2                                               One Dance   \n",
       "3                             Broccoli (feat. Lil Yachty)   \n",
       "4                                         Congratulations   \n",
       "...                                                   ...   \n",
       "681800                                       Intro Bonito   \n",
       "681801  Intro / Mule Skinner Blues (Blue Yodel No. 8) ...   \n",
       "681802                                    Intro / Madness   \n",
       "681803               Intro - Urban Salute to Hector Lavoe   \n",
       "681804                  Look For Me At Jesus' Feet - Live   \n",
       "\n",
       "                                   track_uri  \\\n",
       "0       spotify:track:7KXjTSCq5nL1LoYtL7XAwS   \n",
       "1       spotify:track:7BKLCZ1jbUBVqRi2FVlTVw   \n",
       "2       spotify:track:1xznGGDReH1oQq0xzbwXa3   \n",
       "3       spotify:track:7yyRTcZmCiyzzJlNzGC9Ol   \n",
       "4       spotify:track:3a1lNhkSLSkpJE4MSHpDu9   \n",
       "...                                      ...   \n",
       "681800  spotify:track:19pUiFzM1Lfui5IzvbJInJ   \n",
       "681801  spotify:track:3IOJXkHcwFDTOSLxcAw2XF   \n",
       "681802  spotify:track:62KdOlGDRX7jbQJLIivG5j   \n",
       "681803  spotify:track:5krfvR6iPmNbXalFgmtvPS   \n",
       "681804  spotify:track:1wNYmgrFCHQQeJ1oRKPrvl   \n",
       "\n",
       "                                   artist_uri  \\\n",
       "0       spotify:artist:2YZyLoL8N0Wb9xBt1NhZWg   \n",
       "1       spotify:artist:69GGBxA162lTqCwzJG5jLp   \n",
       "2       spotify:artist:3TVXtAsR1Inumwj472S9r4   \n",
       "3       spotify:artist:5M0lbkGluOPXLeFjApw8r8   \n",
       "4       spotify:artist:246dkjvS1zLTtiykXe5h60   \n",
       "...                                       ...   \n",
       "681800  spotify:artist:6OqhFYFJDnBBHas02HopPT   \n",
       "681801  spotify:artist:64vAECmFoB6mi7n1zTRwR8   \n",
       "681802  spotify:artist:75S63f1AmZUa9gpQvlt5NB   \n",
       "681803  spotify:artist:6P9Adm5Ne2YtzhV1hOjQcC   \n",
       "681804  spotify:artist:01uI1SCsA0pLwWa2ENV6Gv   \n",
       "\n",
       "                                   album_uri  \\\n",
       "0       spotify:album:4eLPsYPBmXABThSJ821sqY   \n",
       "1       spotify:album:0rSLgV8p5FzfnqlEk4GzxE   \n",
       "2       spotify:album:3hARKC8cinq3mZLLAEaBh9   \n",
       "3       spotify:album:0NrZHZ0y5kTO8EHliuUUca   \n",
       "4       spotify:album:5s0rmjP8XOPhP6HhqOhuyC   \n",
       "...                                      ...   \n",
       "681800  spotify:album:2xyl7MxdxOGd7m8qV6mtcM   \n",
       "681801  spotify:album:1XXMBnpx20DkGNyiuf4TPa   \n",
       "681802  spotify:album:6etmKrHivh8W7SouljN2si   \n",
       "681803  spotify:album:4Hf8SuY3DNK07Q8cagjCNR   \n",
       "681804  spotify:album:3FabM2BjqVC3hlIfzP4sA2   \n",
       "\n",
       "                                              playlist_id  playlist_count  \n",
       "0       [17179869726, 34359739337, 17179869700, 171798...            2929  \n",
       "1       [190, 34359738397, 17179869700, 17179869260, 3...            2832  \n",
       "2       [17179869726, 190, 17179869260, 8589935195, 34...            2825  \n",
       "3       [34359738917, 190, 34359738448, 8589935195, 34...            2793  \n",
       "4       [34359738917, 190, 17179869700, 34359738397, 3...            2733  \n",
       "...                                                   ...             ...  \n",
       "681800                                       [8589935151]               1  \n",
       "681801                                      [25769804664]               1  \n",
       "681802                                       [8589934677]               1  \n",
       "681803                                      [17179869244]               1  \n",
       "681804                                              [815]               1  \n",
       "\n",
       "[681805 rows x 6 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate the two dataframes\n",
    "df_final = pd.concat([df_common, df_outter])\n",
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_name</th>\n",
       "      <th>track_uri</th>\n",
       "      <th>artist_uri</th>\n",
       "      <th>album_uri</th>\n",
       "      <th>playlist_id</th>\n",
       "      <th>playlist_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [track_name, track_uri, artist_uri, album_uri, playlist_id, playlist_count]\n",
       "Index: []"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final[df_final.duplicated(subset=['track_uri'], keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the columns that are not needed  track_name, artist_uri, album_uri,\n",
    "df_final = df_final.drop('album_uri', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the column Track_uri, remove the spotify:track: from the values\n",
    "df_final['track_uri'] = df_final['track_uri'].apply(lambda x: x.replace('spotify:track:', ''))\n",
    "# Modify the column artist_uri, remove the spotify:artist: from the values\n",
    "df_final['artist_uri'] = df_final['artist_uri'].apply(lambda x: x.replace('spotify:artist:', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read tje track data\n",
    "df_tracks = pd.read_csv('Dataset/tracks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the id column to track_uri and name to track_name\n",
    "df_tracks = df_tracks.rename(columns={'id': 'track_uri', 'name': 'track_name', 'id_artists': 'artist_uri'})\n",
    "\n",
    "# Modify the column Track_uri, remove the []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two dataframes on the track_uri column, if there is a match, the values will be added to the dataframe\n",
    "# If there is no match, we will keep both dataframes and add NaN values\n",
    "df_final_metadata = pd.merge(df_final, df_tracks, how='outer', on=['track_uri'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_name_x</th>\n",
       "      <th>track_uri</th>\n",
       "      <th>playlist_id</th>\n",
       "      <th>playlist_count</th>\n",
       "      <th>track_name_y</th>\n",
       "      <th>popularity</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>explicit</th>\n",
       "      <th>artists</th>\n",
       "      <th>id_artists</th>\n",
       "      <th>...</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HUMBLE.</td>\n",
       "      <td>7KXjTSCq5nL1LoYtL7XAwS</td>\n",
       "      <td>[17179869726, 34359739337, 17179869700, 171798...</td>\n",
       "      <td>2929.0</td>\n",
       "      <td>HUMBLE.</td>\n",
       "      <td>83.0</td>\n",
       "      <td>177000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['Kendrick Lamar']</td>\n",
       "      <td>['2YZyLoL8N0Wb9xBt1NhZWg']</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.638</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1020</td>\n",
       "      <td>0.000282</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.0958</td>\n",
       "      <td>0.4210</td>\n",
       "      <td>150.011</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Closer</td>\n",
       "      <td>7BKLCZ1jbUBVqRi2FVlTVw</td>\n",
       "      <td>[190, 34359738397, 17179869700, 17179869260, 3...</td>\n",
       "      <td>2832.0</td>\n",
       "      <td>Closer</td>\n",
       "      <td>86.0</td>\n",
       "      <td>244960.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['The Chainsmokers', 'Halsey']</td>\n",
       "      <td>['69GGBxA162lTqCwzJG5jLp', '26VFTg2z8YR0cCuwLz...</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-5.599</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0338</td>\n",
       "      <td>0.414000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1110</td>\n",
       "      <td>0.6610</td>\n",
       "      <td>95.010</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>One Dance</td>\n",
       "      <td>1xznGGDReH1oQq0xzbwXa3</td>\n",
       "      <td>[17179869726, 190, 17179869260, 8589935195, 34...</td>\n",
       "      <td>2825.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Broccoli (feat. Lil Yachty)</td>\n",
       "      <td>7yyRTcZmCiyzzJlNzGC9Ol</td>\n",
       "      <td>[34359738917, 190, 34359738448, 8589935195, 34...</td>\n",
       "      <td>2793.0</td>\n",
       "      <td>Broccoli (feat. Lil Yachty)</td>\n",
       "      <td>68.0</td>\n",
       "      <td>225205.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['Shelley FKA DRAM', 'Lil Yachty']</td>\n",
       "      <td>['5M0lbkGluOPXLeFjApw8r8', '6icQOAFXDZKsumw3YX...</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-7.390</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1310</td>\n",
       "      <td>0.236000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0570</td>\n",
       "      <td>0.7080</td>\n",
       "      <td>145.990</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Congratulations</td>\n",
       "      <td>3a1lNhkSLSkpJE4MSHpDu9</td>\n",
       "      <td>[34359738917, 190, 17179869700, 34359738397, 3...</td>\n",
       "      <td>2733.0</td>\n",
       "      <td>Congratulations</td>\n",
       "      <td>83.0</td>\n",
       "      <td>220293.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['Post Malone', 'Quavo']</td>\n",
       "      <td>['246dkjvS1zLTtiykXe5h60', '0VRj0yCOv2FXJNP47X...</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-4.183</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0363</td>\n",
       "      <td>0.215000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2530</td>\n",
       "      <td>0.4920</td>\n",
       "      <td>123.146</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1207057</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5rgu12WBIHQtvej2MdHSH0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>云与海</td>\n",
       "      <td>50.0</td>\n",
       "      <td>258267.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['阿YueYue']</td>\n",
       "      <td>['1QLBXKM5GCpyQQSVMNZqrZ']</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-7.471</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0292</td>\n",
       "      <td>0.785000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0648</td>\n",
       "      <td>0.2110</td>\n",
       "      <td>131.896</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1207058</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0NuWgxEp51CutD2pJoF4OM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>blind</td>\n",
       "      <td>72.0</td>\n",
       "      <td>153293.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['ROLE MODEL']</td>\n",
       "      <td>['1dy5WNgIKQU6ezkpZs4y8z']</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.223</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0652</td>\n",
       "      <td>0.141000</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>0.0924</td>\n",
       "      <td>0.6860</td>\n",
       "      <td>150.091</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1207059</th>\n",
       "      <td>NaN</td>\n",
       "      <td>27Y1N4Q4U3EfDU5Ubw8ws2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>What They'll Say About Us</td>\n",
       "      <td>70.0</td>\n",
       "      <td>187601.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['FINNEAS']</td>\n",
       "      <td>['37M5pPGs6V1fchFJSgCguX']</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-12.823</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0408</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.0874</td>\n",
       "      <td>0.0663</td>\n",
       "      <td>145.095</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1207060</th>\n",
       "      <td>NaN</td>\n",
       "      <td>45XJsGpFTyzbzeWK8VzR8S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A Day At A Time</td>\n",
       "      <td>58.0</td>\n",
       "      <td>142003.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['Gentle Bones', 'Clara Benin']</td>\n",
       "      <td>['4jGPdu95icCKVF31CcFKbS', '5ebPSE9YI5aLeZ1Z2g...</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-6.212</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0345</td>\n",
       "      <td>0.206000</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.3050</td>\n",
       "      <td>0.4380</td>\n",
       "      <td>90.029</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1207061</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5Ocn6dZ3BJFPWh4ylwFXtn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mar de Emociones</td>\n",
       "      <td>38.0</td>\n",
       "      <td>214360.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['Afrosound']</td>\n",
       "      <td>['0i4Qda0k4nf7jnNHmSNpYv']</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-7.067</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0363</td>\n",
       "      <td>0.105000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2640</td>\n",
       "      <td>0.9750</td>\n",
       "      <td>112.204</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1207062 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        track_name_x               track_uri  \\\n",
       "0                            HUMBLE.  7KXjTSCq5nL1LoYtL7XAwS   \n",
       "1                             Closer  7BKLCZ1jbUBVqRi2FVlTVw   \n",
       "2                          One Dance  1xznGGDReH1oQq0xzbwXa3   \n",
       "3        Broccoli (feat. Lil Yachty)  7yyRTcZmCiyzzJlNzGC9Ol   \n",
       "4                    Congratulations  3a1lNhkSLSkpJE4MSHpDu9   \n",
       "...                              ...                     ...   \n",
       "1207057                          NaN  5rgu12WBIHQtvej2MdHSH0   \n",
       "1207058                          NaN  0NuWgxEp51CutD2pJoF4OM   \n",
       "1207059                          NaN  27Y1N4Q4U3EfDU5Ubw8ws2   \n",
       "1207060                          NaN  45XJsGpFTyzbzeWK8VzR8S   \n",
       "1207061                          NaN  5Ocn6dZ3BJFPWh4ylwFXtn   \n",
       "\n",
       "                                               playlist_id  playlist_count  \\\n",
       "0        [17179869726, 34359739337, 17179869700, 171798...          2929.0   \n",
       "1        [190, 34359738397, 17179869700, 17179869260, 3...          2832.0   \n",
       "2        [17179869726, 190, 17179869260, 8589935195, 34...          2825.0   \n",
       "3        [34359738917, 190, 34359738448, 8589935195, 34...          2793.0   \n",
       "4        [34359738917, 190, 17179869700, 34359738397, 3...          2733.0   \n",
       "...                                                    ...             ...   \n",
       "1207057                                                NaN             NaN   \n",
       "1207058                                                NaN             NaN   \n",
       "1207059                                                NaN             NaN   \n",
       "1207060                                                NaN             NaN   \n",
       "1207061                                                NaN             NaN   \n",
       "\n",
       "                        track_name_y  popularity  duration_ms  explicit  \\\n",
       "0                            HUMBLE.        83.0     177000.0       1.0   \n",
       "1                             Closer        86.0     244960.0       0.0   \n",
       "2                                NaN         NaN          NaN       NaN   \n",
       "3        Broccoli (feat. Lil Yachty)        68.0     225205.0       1.0   \n",
       "4                    Congratulations        83.0     220293.0       1.0   \n",
       "...                              ...         ...          ...       ...   \n",
       "1207057                          云与海        50.0     258267.0       0.0   \n",
       "1207058                        blind        72.0     153293.0       0.0   \n",
       "1207059    What They'll Say About Us        70.0     187601.0       0.0   \n",
       "1207060              A Day At A Time        58.0     142003.0       0.0   \n",
       "1207061             Mar de Emociones        38.0     214360.0       0.0   \n",
       "\n",
       "                                    artists  \\\n",
       "0                        ['Kendrick Lamar']   \n",
       "1            ['The Chainsmokers', 'Halsey']   \n",
       "2                                       NaN   \n",
       "3        ['Shelley FKA DRAM', 'Lil Yachty']   \n",
       "4                  ['Post Malone', 'Quavo']   \n",
       "...                                     ...   \n",
       "1207057                         ['阿YueYue']   \n",
       "1207058                      ['ROLE MODEL']   \n",
       "1207059                         ['FINNEAS']   \n",
       "1207060     ['Gentle Bones', 'Clara Benin']   \n",
       "1207061                       ['Afrosound']   \n",
       "\n",
       "                                                id_artists  ...   key  \\\n",
       "0                               ['2YZyLoL8N0Wb9xBt1NhZWg']  ...   1.0   \n",
       "1        ['69GGBxA162lTqCwzJG5jLp', '26VFTg2z8YR0cCuwLz...  ...   8.0   \n",
       "2                                                      NaN  ...   NaN   \n",
       "3        ['5M0lbkGluOPXLeFjApw8r8', '6icQOAFXDZKsumw3YX...  ...   8.0   \n",
       "4        ['246dkjvS1zLTtiykXe5h60', '0VRj0yCOv2FXJNP47X...  ...   6.0   \n",
       "...                                                    ...  ...   ...   \n",
       "1207057                         ['1QLBXKM5GCpyQQSVMNZqrZ']  ...   0.0   \n",
       "1207058                         ['1dy5WNgIKQU6ezkpZs4y8z']  ...   0.0   \n",
       "1207059                         ['37M5pPGs6V1fchFJSgCguX']  ...   7.0   \n",
       "1207060  ['4jGPdu95icCKVF31CcFKbS', '5ebPSE9YI5aLeZ1Z2g...  ...  10.0   \n",
       "1207061                         ['0i4Qda0k4nf7jnNHmSNpYv']  ...   6.0   \n",
       "\n",
       "         loudness  mode  speechiness  acousticness  instrumentalness  \\\n",
       "0          -6.638   0.0       0.1020      0.000282          0.000054   \n",
       "1          -5.599   1.0       0.0338      0.414000          0.000000   \n",
       "2             NaN   NaN          NaN           NaN               NaN   \n",
       "3          -7.390   1.0       0.1310      0.236000          0.000000   \n",
       "4          -4.183   1.0       0.0363      0.215000          0.000000   \n",
       "...           ...   ...          ...           ...               ...   \n",
       "1207057    -7.471   0.0       0.0292      0.785000          0.000000   \n",
       "1207058    -5.223   1.0       0.0652      0.141000          0.000297   \n",
       "1207059   -12.823   0.0       0.0408      0.895000          0.000150   \n",
       "1207060    -6.212   1.0       0.0345      0.206000          0.000003   \n",
       "1207061    -7.067   1.0       0.0363      0.105000          0.000000   \n",
       "\n",
       "         liveness  valence    tempo  time_signature  \n",
       "0          0.0958   0.4210  150.011             4.0  \n",
       "1          0.1110   0.6610   95.010             4.0  \n",
       "2             NaN      NaN      NaN             NaN  \n",
       "3          0.0570   0.7080  145.990             4.0  \n",
       "4          0.2530   0.4920  123.146             4.0  \n",
       "...           ...      ...      ...             ...  \n",
       "1207057    0.0648   0.2110  131.896             4.0  \n",
       "1207058    0.0924   0.6860  150.091             4.0  \n",
       "1207059    0.0874   0.0663  145.095             4.0  \n",
       "1207060    0.3050   0.4380   90.029             4.0  \n",
       "1207061    0.2640   0.9750  112.204             4.0  \n",
       "\n",
       "[1207062 rows x 23 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['track_name_x', 'track_uri', 'artist_uri_x', 'playlist_id',\n",
       "       'playlist_count', 'track_name_y', 'popularity', 'duration_ms',\n",
       "       'explicit', 'artists', 'artist_uri_y', 'release_date', 'danceability',\n",
       "       'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness',\n",
       "       'instrumentalness', 'liveness', 'valence', 'tempo', 'time_signature'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_metadata.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1207062"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unique tracks_uri indf_final_metadata\n",
    "len(df_final_metadata['track_uri'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the column track_name_x to track_name if there is a match, if nan values, the column will be renamed to track_name_y\n",
    "df_final_metadata = df_final_metadata.rename(columns={'track_name_x': 'track_name'})\n",
    "\n",
    "# if track_name is nan, the value of track_name_y will be assigned to track_name\n",
    "df_final_metadata['track_name'] = df_final_metadata.apply(lambda x: x['track_name_y'] if pd.isnull(x['track_name']) else x['track_name'], axis=1)\n",
    "\n",
    "# Rwmove the column artist_uri_x to artist_uri if there is a match, if nan values, the column will be renamed to artist_uri_y\n",
    "df_final_metadata = df_final_metadata.rename(columns={'artist_uri_y': 'artist_uri'})\n",
    "\n",
    "# if artist_uri is nan, the value of artist_uri_y will be assigned to artist_uri\n",
    "df_final_metadata['artist_uri'] = df_final_metadata.apply(lambda x: x['artist_uri_x'] if pd.isnull(x['artist_uri']) else x['artist_uri'], axis=1)\n",
    "\n",
    "\n",
    "# Drop the columns that are not needed\n",
    "df_final_metadata = df_final_metadata.drop(['track_name_y', 'artist_uri_x'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1207062"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_final_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_name</th>\n",
       "      <th>track_uri</th>\n",
       "      <th>playlist_id</th>\n",
       "      <th>playlist_count</th>\n",
       "      <th>popularity</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>explicit</th>\n",
       "      <th>artists</th>\n",
       "      <th>artist_uri</th>\n",
       "      <th>release_date</th>\n",
       "      <th>...</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>One Dance</td>\n",
       "      <td>1xznGGDReH1oQq0xzbwXa3</td>\n",
       "      <td>[17179869726, 190, 17179869260, 8589935195, 34...</td>\n",
       "      <td>2825.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3TVXtAsR1Inumwj472S9r4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Roses</td>\n",
       "      <td>6O6M7pJLABmfBRoGZMu76Y</td>\n",
       "      <td>[34359739337, 34359738397, 17179869700, 343597...</td>\n",
       "      <td>2310.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69GGBxA162lTqCwzJG5jLp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Gold Digger</td>\n",
       "      <td>5XJJdNPkwmbUwE79gv0NxK</td>\n",
       "      <td>[17179869726, 34359739337, 34359738917, 190, 3...</td>\n",
       "      <td>2229.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5K4W6rqBFWDnAN6FQUkS6x</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Redbone</td>\n",
       "      <td>3kxfsdsCpFgN412fpnW85Y</td>\n",
       "      <td>[17179869726, 34359739337, 34359738917, 190, 1...</td>\n",
       "      <td>2233.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>73sIBHcqh3Z3NyqHKZ7FOL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Despacito - Remix</td>\n",
       "      <td>5CtI0qwDJkDQGwXD1H1cLb</td>\n",
       "      <td>[34359739337, 190, 34359738397, 34359738448, 3...</td>\n",
       "      <td>2233.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4V8Sr092TqfHkfAA5fXXqG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681800</th>\n",
       "      <td>Intro Bonito</td>\n",
       "      <td>19pUiFzM1Lfui5IzvbJInJ</td>\n",
       "      <td>[8589935151]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6OqhFYFJDnBBHas02HopPT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681801</th>\n",
       "      <td>Intro / Mule Skinner Blues (Blue Yodel No. 8) ...</td>\n",
       "      <td>3IOJXkHcwFDTOSLxcAw2XF</td>\n",
       "      <td>[25769804664]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64vAECmFoB6mi7n1zTRwR8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681802</th>\n",
       "      <td>Intro / Madness</td>\n",
       "      <td>62KdOlGDRX7jbQJLIivG5j</td>\n",
       "      <td>[8589934677]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75S63f1AmZUa9gpQvlt5NB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681803</th>\n",
       "      <td>Intro - Urban Salute to Hector Lavoe</td>\n",
       "      <td>5krfvR6iPmNbXalFgmtvPS</td>\n",
       "      <td>[17179869244]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6P9Adm5Ne2YtzhV1hOjQcC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681804</th>\n",
       "      <td>Look For Me At Jesus' Feet - Live</td>\n",
       "      <td>1wNYmgrFCHQQeJ1oRKPrvl</td>\n",
       "      <td>[815]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01uI1SCsA0pLwWa2ENV6Gv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>620390 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               track_name  \\\n",
       "2                                               One Dance   \n",
       "12                                                  Roses   \n",
       "18                                            Gold Digger   \n",
       "19                                                Redbone   \n",
       "22                                      Despacito - Remix   \n",
       "...                                                   ...   \n",
       "681800                                       Intro Bonito   \n",
       "681801  Intro / Mule Skinner Blues (Blue Yodel No. 8) ...   \n",
       "681802                                    Intro / Madness   \n",
       "681803               Intro - Urban Salute to Hector Lavoe   \n",
       "681804                  Look For Me At Jesus' Feet - Live   \n",
       "\n",
       "                     track_uri  \\\n",
       "2       1xznGGDReH1oQq0xzbwXa3   \n",
       "12      6O6M7pJLABmfBRoGZMu76Y   \n",
       "18      5XJJdNPkwmbUwE79gv0NxK   \n",
       "19      3kxfsdsCpFgN412fpnW85Y   \n",
       "22      5CtI0qwDJkDQGwXD1H1cLb   \n",
       "...                        ...   \n",
       "681800  19pUiFzM1Lfui5IzvbJInJ   \n",
       "681801  3IOJXkHcwFDTOSLxcAw2XF   \n",
       "681802  62KdOlGDRX7jbQJLIivG5j   \n",
       "681803  5krfvR6iPmNbXalFgmtvPS   \n",
       "681804  1wNYmgrFCHQQeJ1oRKPrvl   \n",
       "\n",
       "                                              playlist_id  playlist_count  \\\n",
       "2       [17179869726, 190, 17179869260, 8589935195, 34...          2825.0   \n",
       "12      [34359739337, 34359738397, 17179869700, 343597...          2310.0   \n",
       "18      [17179869726, 34359739337, 34359738917, 190, 3...          2229.0   \n",
       "19      [17179869726, 34359739337, 34359738917, 190, 1...          2233.0   \n",
       "22      [34359739337, 190, 34359738397, 34359738448, 3...          2233.0   \n",
       "...                                                   ...             ...   \n",
       "681800                                       [8589935151]             1.0   \n",
       "681801                                      [25769804664]             1.0   \n",
       "681802                                       [8589934677]             1.0   \n",
       "681803                                      [17179869244]             1.0   \n",
       "681804                                              [815]             1.0   \n",
       "\n",
       "        popularity  duration_ms  explicit artists              artist_uri  \\\n",
       "2              NaN          NaN       NaN     NaN  3TVXtAsR1Inumwj472S9r4   \n",
       "12             NaN          NaN       NaN     NaN  69GGBxA162lTqCwzJG5jLp   \n",
       "18             NaN          NaN       NaN     NaN  5K4W6rqBFWDnAN6FQUkS6x   \n",
       "19             NaN          NaN       NaN     NaN  73sIBHcqh3Z3NyqHKZ7FOL   \n",
       "22             NaN          NaN       NaN     NaN  4V8Sr092TqfHkfAA5fXXqG   \n",
       "...            ...          ...       ...     ...                     ...   \n",
       "681800         NaN          NaN       NaN     NaN  6OqhFYFJDnBBHas02HopPT   \n",
       "681801         NaN          NaN       NaN     NaN  64vAECmFoB6mi7n1zTRwR8   \n",
       "681802         NaN          NaN       NaN     NaN  75S63f1AmZUa9gpQvlt5NB   \n",
       "681803         NaN          NaN       NaN     NaN  6P9Adm5Ne2YtzhV1hOjQcC   \n",
       "681804         NaN          NaN       NaN     NaN  01uI1SCsA0pLwWa2ENV6Gv   \n",
       "\n",
       "       release_date  ...  key  loudness  mode  speechiness  acousticness  \\\n",
       "2               NaN  ...  NaN       NaN   NaN          NaN           NaN   \n",
       "12              NaN  ...  NaN       NaN   NaN          NaN           NaN   \n",
       "18              NaN  ...  NaN       NaN   NaN          NaN           NaN   \n",
       "19              NaN  ...  NaN       NaN   NaN          NaN           NaN   \n",
       "22              NaN  ...  NaN       NaN   NaN          NaN           NaN   \n",
       "...             ...  ...  ...       ...   ...          ...           ...   \n",
       "681800          NaN  ...  NaN       NaN   NaN          NaN           NaN   \n",
       "681801          NaN  ...  NaN       NaN   NaN          NaN           NaN   \n",
       "681802          NaN  ...  NaN       NaN   NaN          NaN           NaN   \n",
       "681803          NaN  ...  NaN       NaN   NaN          NaN           NaN   \n",
       "681804          NaN  ...  NaN       NaN   NaN          NaN           NaN   \n",
       "\n",
       "        instrumentalness  liveness  valence  tempo  time_signature  \n",
       "2                    NaN       NaN      NaN    NaN             NaN  \n",
       "12                   NaN       NaN      NaN    NaN             NaN  \n",
       "18                   NaN       NaN      NaN    NaN             NaN  \n",
       "19                   NaN       NaN      NaN    NaN             NaN  \n",
       "22                   NaN       NaN      NaN    NaN             NaN  \n",
       "...                  ...       ...      ...    ...             ...  \n",
       "681800               NaN       NaN      NaN    NaN             NaN  \n",
       "681801               NaN       NaN      NaN    NaN             NaN  \n",
       "681802               NaN       NaN      NaN    NaN             NaN  \n",
       "681803               NaN       NaN      NaN    NaN             NaN  \n",
       "681804               NaN       NaN      NaN    NaN             NaN  \n",
       "\n",
       "[620390 rows x 22 columns]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the number of tracks that have null values in the column playlist_id\n",
    "df_final_metadata[df_final_metadata['explicit'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61415, 22)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataframe to a csv file\n",
    "df_final_metadata.to_csv('Dataset/1,2M_Tracks_with_playlists.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e27d09a1f32823a4988b211562278e77704b68b9cb89de75a81e314acea13ca6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
