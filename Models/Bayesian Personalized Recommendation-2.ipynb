{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fdf6022",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn import cross_validation, linear_model\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import datasets\n",
    "import random\n",
    "import time\n",
    "import pylab as pl\n",
    "from sklearn import metrics, ensemble\n",
    "import xgboost as xgb\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('ggplot')\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import scipy.sparse as sp\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d604400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>song_id</th>\n",
       "      <th>listen_count</th>\n",
       "      <th>track_id</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>track_name</th>\n",
       "      <th>track_uri</th>\n",
       "      <th>popularity</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>explicit</th>\n",
       "      <th>...</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>artist_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>SOBSUJE12A6D4F8CF5</td>\n",
       "      <td>2</td>\n",
       "      <td>TRPLAXZ128F4292406</td>\n",
       "      <td>Jorge Drexler</td>\n",
       "      <td>12 segundos de oscuridad</td>\n",
       "      <td>2ECKXkpPAxky87ohawpaeD</td>\n",
       "      <td>37</td>\n",
       "      <td>246826</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.176</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0327</td>\n",
       "      <td>0.11900</td>\n",
       "      <td>0.000412</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.0396</td>\n",
       "      <td>126.051</td>\n",
       "      <td>4</td>\n",
       "      <td>4ssUf5gLb1GBLxi1BhPrVt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>SOBXHDL12A81C204C0</td>\n",
       "      <td>1</td>\n",
       "      <td>TRHNCIR128F42334A5</td>\n",
       "      <td>Kanye West</td>\n",
       "      <td>Stronger</td>\n",
       "      <td>4fzsfWzRhPawzqhX8Qt9F3</td>\n",
       "      <td>82</td>\n",
       "      <td>311867</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.858</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1530</td>\n",
       "      <td>0.00564</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.4900</td>\n",
       "      <td>103.992</td>\n",
       "      <td>4</td>\n",
       "      <td>5K4W6rqBFWDnAN6FQUkS6x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>SOBXHDL12A81C204C0</td>\n",
       "      <td>1</td>\n",
       "      <td>TRUATNS128F423457D</td>\n",
       "      <td>Kanye West</td>\n",
       "      <td>Stronger</td>\n",
       "      <td>4fzsfWzRhPawzqhX8Qt9F3</td>\n",
       "      <td>82</td>\n",
       "      <td>311867</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.858</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1530</td>\n",
       "      <td>0.00564</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.4900</td>\n",
       "      <td>103.992</td>\n",
       "      <td>4</td>\n",
       "      <td>5K4W6rqBFWDnAN6FQUkS6x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>SOBYHAJ12A6701BF1D</td>\n",
       "      <td>1</td>\n",
       "      <td>TRYBNIB128F428E704</td>\n",
       "      <td>Jack Johnson</td>\n",
       "      <td>Constellations</td>\n",
       "      <td>3deZQXBY8CJFbrTc2PbU34</td>\n",
       "      <td>59</td>\n",
       "      <td>201640</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.640</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0355</td>\n",
       "      <td>0.46800</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.4430</td>\n",
       "      <td>122.012</td>\n",
       "      <td>4</td>\n",
       "      <td>3GBPw9NK25X1Wt2OUvOwY3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>SOEWFWM12A8C1308BA</td>\n",
       "      <td>1</td>\n",
       "      <td>TRLQPQJ128F42AA94F</td>\n",
       "      <td>Gipsy Kings</td>\n",
       "      <td>Soy</td>\n",
       "      <td>076jKe7yfP979o1QLKMIA2</td>\n",
       "      <td>47</td>\n",
       "      <td>189987</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.321</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0653</td>\n",
       "      <td>0.29700</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.9050</td>\n",
       "      <td>114.656</td>\n",
       "      <td>4</td>\n",
       "      <td>3jc496ljiyrS3ECrD7QiqL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    user_id             song_id  listen_count  \\\n",
       "0  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOBSUJE12A6D4F8CF5             2   \n",
       "1  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOBXHDL12A81C204C0             1   \n",
       "2  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOBXHDL12A81C204C0             1   \n",
       "3  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOBYHAJ12A6701BF1D             1   \n",
       "4  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOEWFWM12A8C1308BA             1   \n",
       "\n",
       "             track_id    artist_name                track_name  \\\n",
       "0  TRPLAXZ128F4292406  Jorge Drexler  12 segundos de oscuridad   \n",
       "1  TRHNCIR128F42334A5     Kanye West                  Stronger   \n",
       "2  TRUATNS128F423457D     Kanye West                  Stronger   \n",
       "3  TRYBNIB128F428E704   Jack Johnson            Constellations   \n",
       "4  TRLQPQJ128F42AA94F    Gipsy Kings                       Soy   \n",
       "\n",
       "                track_uri  popularity  duration_ms  explicit  ... loudness  \\\n",
       "0  2ECKXkpPAxky87ohawpaeD          37       246826         0  ...   -8.176   \n",
       "1  4fzsfWzRhPawzqhX8Qt9F3          82       311867         1  ...   -7.858   \n",
       "2  4fzsfWzRhPawzqhX8Qt9F3          82       311867         1  ...   -7.858   \n",
       "3  3deZQXBY8CJFbrTc2PbU34          59       201640         0  ...  -12.640   \n",
       "4  076jKe7yfP979o1QLKMIA2          47       189987         0  ...  -12.321   \n",
       "\n",
       "   mode  speechiness  acousticness  instrumentalness  liveness  valence  \\\n",
       "0     0       0.0327       0.11900          0.000412     0.103   0.0396   \n",
       "1     0       0.1530       0.00564          0.000000     0.408   0.4900   \n",
       "2     0       0.1530       0.00564          0.000000     0.408   0.4900   \n",
       "3     1       0.0355       0.46800          0.000043     0.117   0.4430   \n",
       "4     0       0.0653       0.29700          0.000267     0.127   0.9050   \n",
       "\n",
       "     tempo  time_signature               artist_id  \n",
       "0  126.051               4  4ssUf5gLb1GBLxi1BhPrVt  \n",
       "1  103.992               4  5K4W6rqBFWDnAN6FQUkS6x  \n",
       "2  103.992               4  5K4W6rqBFWDnAN6FQUkS6x  \n",
       "3  122.012               4  3GBPw9NK25X1Wt2OUvOwY3  \n",
       "4  114.656               4  3jc496ljiyrS3ECrD7QiqL  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(\"../user_track_df.parquet\", engine='pyarrow')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae748774",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will implement BPR using matrix factorization, which means taking the interaction matrix R\n",
    "#of size (all users x all times) and factoring it into matrix U of size (all users x latent features)\n",
    "#and V of size (latent features x all items).  In the end we will have R ~ UxV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a0a9cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stochastic Gradient Descent (SGD) will be used in order to arrive at this approximation. \n",
    "#It works by initializing U and V with uniformly random values and then, using the optimization ciretrion\n",
    "#from before, continuously updating them with new values tomaximize the posterior porbability\n",
    "#i.e getting an increasing probability for R=UxVV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f050208",
   "metadata": {},
   "source": [
    "Feature engineering & Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f083f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[:20000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "deecde28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping unnecessary columns\n",
    "df = df.drop(['track_id', 'track_uri'], axis=1)\n",
    "\n",
    "#afterwards, we can see that the IDs given in the table are string types\n",
    "#therefore, for this analysis we are going to drop them and instead encode the artist_name, track_name\n",
    "#we are not going to drop user_id and we will encode it instead\n",
    "df = df.drop(['song_id', 'artist_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23f2e068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "listen_count            2.000000\n",
      "popularity             22.000000\n",
      "duration_ms         66240.000000\n",
      "explicit                0.000000\n",
      "danceability            0.217250\n",
      "energy                  0.316000\n",
      "key                     7.000000\n",
      "loudness                4.317000\n",
      "mode                    1.000000\n",
      "speechiness             0.032500\n",
      "acousticness            0.288082\n",
      "instrumentalness        0.007700\n",
      "liveness                0.165300\n",
      "valence                 0.399000\n",
      "tempo                  39.212000\n",
      "time_signature          0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#based on the boxplots presented in EDA we can observe that we might be dealing with outliers\n",
    "#we will tackle this with IQR\n",
    "Q1 = df.quantile(0.25)\n",
    "Q3 = df.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "print(IQR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7855bcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9777, 20)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[~((df < (Q1 - 1.5 * IQR)) |(df > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "452e56ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a3174e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert artists names into numerical IDs\n",
    "df['user_id_num'] = df['user_id'].astype(\"category\").cat.codes\n",
    "df['artist_id'] = df['artist_name'].astype(\"category\").cat.codes\n",
    "df['track_id'] = df['track_name'].astype(\"category\").cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28271e61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#drop columns that have categorical features such as the name of the artist and track.\n",
    "#usually we would encode this; however, there's no need as we already have the ids and this way\n",
    "#we would just have several columns depicting same values that is unnecessary\n",
    "\n",
    "#before we do this we will create a lookup frame so we can get the artist names back in readable form later\n",
    "item_lookup = df[['artist_id', 'artist_name']].drop_duplicates()\n",
    "item_lookup['artist_id'] = item_lookup.artist_id.astype(str)\n",
    "\n",
    "#item_lookup_track = df[['track_id', 'track_name']].drop_duplicates()\n",
    "#item_lookup_track['track_id'] = item_lookup_track.track_id.astype(str)\n",
    "\n",
    "#dropping the columns\n",
    "df = df.drop(['track_name', 'artist_name', 'user_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fbc4055f",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_lookup = item_lookup.rename(columns={'A': 'X'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2443aada",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'artist_name': 'artist'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3201c24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['listen_count', 'popularity', 'duration_ms', 'explicit', 'release_date',\n",
       "       'danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness',\n",
       "       'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo',\n",
       "       'time_signature', 'user_id_num', 'artist_id', 'track_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking the columns\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e65e9a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop any rows with 0 plays\n",
    "df = df.loc[df.listen_count != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "382d29f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists of all users, artists and plays\n",
    "users = list(np.sort(df.user_id_num.unique()))\n",
    "artists = list(np.sort(df.artist_id.unique()))\n",
    "plays = list(df.listen_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "38843617",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get the rows and columns for our new matrix\n",
    "rows = df.user_id_num.astype(float)\n",
    "cols = df.artist_id.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db80bd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contruct a sparse matrix for our users and items containing number of plays\n",
    "data_sparse = sp.csr_matrix((plays, (rows, cols)), shape=(len(users), len(artists)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "645e1108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the values of our matrix as a list of user ids\n",
    "# and item ids. Note that our lists have the same length\n",
    "# as each user id repeats one time for each played artist.\n",
    "uids, iids = data_sparse.nonzero()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b540a8",
   "metadata": {},
   "source": [
    "Defining Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7854db26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------\n",
    "# HYPERPARAMS\n",
    "#-------------\n",
    "\n",
    "epochs = 50 #50\n",
    "batches = 30 #30\n",
    "num_factors = 64 # Number of latent features\n",
    "\n",
    "# Independent lambda regularization values \n",
    "# for user, items and bias.\n",
    "lambda_user = 0.0000001\n",
    "lambda_item = 0.0000001\n",
    "lambda_bias = 0.0000001\n",
    "\n",
    "# Our learning rate \n",
    "lr = 0.005\n",
    "\n",
    "# How many (u,i,j) triplets we sample for each batch\n",
    "samples = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee41d8af",
   "metadata": {},
   "source": [
    "Defining Tensorflow Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9183cadb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.377 | AUC: 0.844: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1500/1500 [00:56<00:00, 26.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "-------Similar Artists-------\n",
      "            artist      score\n",
      "0         Coldplay  56.910358\n",
      "1      Evanescence  27.507435\n",
      "2      The Killers  25.177402\n",
      "3        Radiohead  25.068197\n",
      "4          Cartola  25.054844\n",
      "5   The Black Keys  24.249895\n",
      "6      Miley Cyrus  23.838608\n",
      "7          Rihanna  23.540762\n",
      "8  Jimmy Eat World  22.593998\n",
      "9         Bon Jovi  22.531239\n",
      "\n",
      "\n",
      "-------Recommendations-------\n",
      "                   artist     score\n",
      "0                Coldplay  3.709384\n",
      "1             OneRepublic  3.541508\n",
      "2                 Cartola  3.215309\n",
      "3                Bon Jovi  3.115548\n",
      "4            Taylor Swift  3.090174\n",
      "5           Justin Bieber  3.059061\n",
      "6                 La Roux  2.971563\n",
      "7             The Killers  2.906898\n",
      "8             Miley Cyrus  2.905311\n",
      "9  Florence + The Machine  2.823690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "#-------------------------\n",
    "# TENSORFLOW GRAPH\n",
    "#-------------------------\n",
    "\n",
    "# Set up our Tensorflow graph\n",
    "graph = tf.Graph()\n",
    "\n",
    "def init_variable(size, dim, name=None):\n",
    "    '''\n",
    "    Helper function to initialize a new variable with\n",
    "    uniform random values.\n",
    "    '''\n",
    "    std = np.sqrt(2 / dim)\n",
    "    return tf.Variable(tf.random.uniform([size, dim], -std, std), name=name)\n",
    "\n",
    "\n",
    "def embed(inputs, size, dim, name=None):\n",
    "    '''\n",
    "    Helper function to get a Tensorflow variable and create\n",
    "    an embedding lookup to map our user and item\n",
    "    indices to vectors.\n",
    "    '''\n",
    "    emb = init_variable(size, dim, name)\n",
    "    return tf.nn.embedding_lookup(emb, inputs)\n",
    "\n",
    "\n",
    "def get_variable(graph, session, name):\n",
    "    '''\n",
    "    Helper function to get the value of a\n",
    "    Tensorflow variable by name.\n",
    "    '''\n",
    "    v = graph.get_operation_by_name(name)\n",
    "    v = v.values()[0]\n",
    "    v = v.eval(session=session)\n",
    "    return v\n",
    "\n",
    "with graph.as_default():\n",
    "    '''\n",
    "    Loss function: \n",
    "    -SUM ln Ïƒ(xui - xuj) + Î»(w1)**2 + Î»(w2)**2 + Î»(w3)**2 ...\n",
    "    ln = the natural log\n",
    "    Ïƒ(xuij) = the sigmoid function of xuij.\n",
    "    Î» = lambda regularization value.\n",
    "    ||W||**2 = the squared L2 norm of our model parameters.\n",
    "    '''\n",
    "\n",
    "    # Input into our model, in this case our user (u),\n",
    "    # known item (i) an unknown item (i) triplets.\n",
    "    u = tf.placeholder(tf.int32, shape=(None, 1))\n",
    "    i = tf.placeholder(tf.int32, shape=(None, 1))\n",
    "    j = tf.placeholder(tf.int32, shape=(None, 1))\n",
    "\n",
    "    # User feature embedding\n",
    "    u_factors = tf.Variable(tf.random_normal([len(users), num_factors]), name='user_factors') # U matrix\n",
    "\n",
    "    # Known and unknown item embeddings\n",
    "    item_factors = tf.Variable(tf.random_normal([len(artists), num_factors]), name='item_factors') # V matrix\n",
    "    i_factors = tf.nn.embedding_lookup(item_factors, i)\n",
    "    j_factors = tf.nn.embedding_lookup(item_factors, j)\n",
    "\n",
    "    # i and j bias embeddings.\n",
    "    item_bias = tf.Variable(tf.zeros([len(artists), 1]), name='item_bias')\n",
    "    i_bias = tf.nn.embedding_lookup(item_bias, i)\n",
    "    i_bias = tf.reshape(i_bias, [-1, 1])\n",
    "    j_bias = tf.nn.embedding_lookup(item_bias, j)\n",
    "    j_bias = tf.reshape(j_bias, [-1, 1])\n",
    "\n",
    "    # Calculate the dot product + bias for known and unknown\n",
    "    # item to get xui and xuj.\n",
    "    xui = i_bias + tf.reduce_sum(tf.multiply(u_factors, i_factors), axis=2)\n",
    "    xuj = j_bias + tf.reduce_sum(tf.multiply(u_factors, j_factors), axis=2)\n",
    "\n",
    "    # We calculate xuij.\n",
    "    xuij = xui - xuj\n",
    "\n",
    "    # Calculate the mean AUC (area under curve).\n",
    "    # if xuij is greater than 0, that means that \n",
    "    # xui is greater than xuj (and thats what we want).\n",
    "    u_auc = tf.reduce_mean(tf.cast(tf.greater(xuij, 0), tf.float32))\n",
    "\n",
    "    # Output the AUC value to tensorboard for monitoring.\n",
    "    tf.summary.scalar('auc', u_auc)\n",
    "\n",
    "    # Calculate the squared L2 norm ||W||**2 multiplied by Î».\n",
    "    l2_norm = tf.add_n([\n",
    "        lambda_user * tf.reduce_sum(tf.multiply(u_factors, u_factors)),\n",
    "        lambda_item * tf.reduce_sum(tf.multiply(i_factors, i_factors)),\n",
    "        lambda_item * tf.reduce_sum(tf.multiply(j_factors, j_factors)),\n",
    "        lambda_bias * tf.reduce_sum(tf.multiply(i_bias, i_bias)),\n",
    "        lambda_bias * tf.reduce_sum(tf.multiply(j_bias, j_bias))\n",
    "        ])\n",
    "\n",
    "    # Calculate the loss as -ln Ïƒ(Xuij) + ||W||**2\n",
    "    loss = -tf.reduce_mean(tf.log(tf.sigmoid(xuij))) + l2_norm\n",
    "\n",
    "    # Train using the Adam optimizer to minimize \n",
    "    # our loss function.\n",
    "    opt = tf.train.AdamOptimizer(learning_rate=lr)\n",
    "    step = opt.minimize(loss)\n",
    "\n",
    "    # Initialize all tensorflow variables.\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    #-----------------------\n",
    "    # FIND SIMILAR ARTISTS\n",
    "    #-----------------------\n",
    "\n",
    "    def find_similar_artists(artist=None, num_items=10):\n",
    "        \"\"\"Find artists similar to an artist.\n",
    "        Args:\n",
    "            artist (str): The name of the artist we want to find similar artists for\n",
    "            num_items (int): How many similar artists we want to return.\n",
    "        Returns:\n",
    "            similar (pandas.DataFrame): DataFrame with num_items artist names and scores\n",
    "        \"\"\"\n",
    "\n",
    "        # Grab our User matrix U\n",
    "        user_vecs = get_variable(graph, sess, 'user_factors')\n",
    "\n",
    "        # Grab our Item matrix V\n",
    "        item_vecs = get_variable(graph, sess, 'item_factors')\n",
    "\n",
    "        # Grab our item bias\n",
    "        item_bi = get_variable(graph, sess, 'item_bias').reshape(-1)\n",
    "\n",
    "        # Get the item id for Lady GaGa\n",
    "        item_id = int(item_lookup[item_lookup.artist_name == artist]['artist_id'])\n",
    "\n",
    "        # Get the item vector for our item_id and transpose it.\n",
    "        item_vec = item_vecs[item_id].T\n",
    "\n",
    "        # Calculate the similarity between Lady GaGa and all other artists\n",
    "        # by multiplying the item vector with our item_matrix\n",
    "        scores = np.add(item_vecs.dot(item_vec), item_bi).reshape(1,-1)[0]\n",
    "\n",
    "        # Get the indices for the top 10 scores\n",
    "        top_10 = np.argsort(scores)[::-1][:num_items]\n",
    "\n",
    "        # We then use our lookup table to grab the names of these indices\n",
    "        # and add it along with its score to a pandas dataframe.\n",
    "        artists, artist_scores = [], []\n",
    "        \n",
    "        for idx in top_10:\n",
    "            artists.append(item_lookup.artist_name.loc[item_lookup.artist_id == str(idx)].iloc[0])\n",
    "            artist_scores.append(scores[idx])\n",
    "\n",
    "        similar = pd.DataFrame({'artist': artists, 'score': artist_scores})\n",
    "\n",
    "        return similar\n",
    "\n",
    "    #---------------------\n",
    "    # MAKE RECOMMENDATION\n",
    "    #---------------------\n",
    "\n",
    "    def make_recommendation(user_id=None, num_items=10):\n",
    "        \"\"\"Recommend items for a given user given a trained model\n",
    "        Args:\n",
    "            user_id (int): The id of the user we want to create recommendations for.\n",
    "            num_items (int): How many recommendations we want to return.\n",
    "        Returns:\n",
    "            recommendations (pandas.DataFrame): DataFrame with num_items artist names and scores\n",
    "        \"\"\"\n",
    "\n",
    "        # Grab our user matrix U\n",
    "        user_vecs = get_variable(graph, sess, 'user_factors')\n",
    "\n",
    "        # Grab our item matrix V\n",
    "        item_vecs = get_variable(graph, sess, 'item_factors')\n",
    "\n",
    "        # Grab our item bias\n",
    "        item_bi = get_variable(graph, sess, 'item_bias').reshape(-1)\n",
    "\n",
    "        # Calculate the score for our user for all items. \n",
    "        rec_vector = np.add(user_vecs[user_id, :].dot(item_vecs.T), item_bi)\n",
    "\n",
    "        # Grab the indices of the top users\n",
    "        item_idx = np.argsort(rec_vector)[::-1][:num_items]\n",
    "\n",
    "        # Map the indices to artist names and add to dataframe along with scores.\n",
    "        artists, scores = [], []\n",
    "\n",
    "        for idx in item_idx:\n",
    "            artists.append(item_lookup.artist_name.loc[item_lookup.artist_id == str(idx)].iloc[0])\n",
    "            scores.append(rec_vector[idx])\n",
    "\n",
    "        recommendations = pd.DataFrame({'artist': artists, 'score': scores})\n",
    "\n",
    "        return recommendations\n",
    "\n",
    "\n",
    "    #------------------\n",
    "    # GRAPH EXECUTION\n",
    "    #------------------\n",
    "\n",
    "    # Run the session with the constructed graph.\n",
    "    with tf.Session(config=None, graph=graph) as sess:\n",
    "        # Initialize the variables in the graph.\n",
    "        sess.run(init)\n",
    "\n",
    "        # This has nothing to do with TensorFlow but gives\n",
    "        # us a nice progress bar for the training.\n",
    "        progress = tqdm(total=batches*epochs)\n",
    "\n",
    "        for _ in range(epochs):\n",
    "            for _ in range(batches):\n",
    "                # We want to sample one known and one unknown \n",
    "                # item for each user. \n",
    "\n",
    "                # First we sample 15000 uniform indices.\n",
    "                idx = np.random.randint(low=0, high=len(uids), size=samples)\n",
    "\n",
    "                # We then grab the users matching those indices.\n",
    "                batch_u = uids[idx].reshape(-1, 1)\n",
    "\n",
    "                # Then the known items for those users.\n",
    "                batch_i = iids[idx].reshape(-1, 1)\n",
    "\n",
    "                # Lastly we randomly sample one unknown item for each user.\n",
    "                batch_j = np.random.randint(\n",
    "                        low=0, high=len(artists), size=(samples, 1), dtype='int32')\n",
    "\n",
    "                # Feed our users, known and unknown items to\n",
    "                # our tensorflow graph. \n",
    "                feed_dict = { u: batch_u, i: batch_i, j: batch_j }\n",
    "\n",
    "                # We run the session.\n",
    "                _, l, auc = sess.run([step, loss, u_auc], feed_dict)\n",
    "\n",
    "            progress.update(batches)\n",
    "            progress.set_description('Loss: %.3f | AUC: %.3f' % (l, auc))\n",
    "\n",
    "        progress.close()\n",
    "\n",
    "        print(\"\\n\")\n",
    "\n",
    "        print(\"-------Similar Artists-------\")\n",
    "\n",
    "        print(find_similar_artists(artist='Coldplay'))\n",
    "\n",
    "        print(\"\\n\")\n",
    "\n",
    "        print(\"-------Recommendations-------\")\n",
    "\n",
    "        print(make_recommendation(user_id=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
